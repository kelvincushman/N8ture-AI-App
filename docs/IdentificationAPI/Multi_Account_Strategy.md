# Multi-Account Strategy for Security Research

**‚ö†Ô∏è DISCLAIMER:** This document is for authorized security research purposes only. Use these techniques only with explicit permission from the API provider to demonstrate vulnerabilities.

---

## Overview

This strategy demonstrates how an attacker could use multiple free API accounts with proxy rotation to collect large-scale training data at minimal cost.

### Key Metrics

| Metric | Value |
| :--- | :--- |
| **Number of accounts** | 20 |
| **Free calls per account/day** | 500 |
| **Total free calls per day** | 10,000 |
| **Total free calls per month** | 300,000 |
| **Cost** | $48/month (proxies only) |
| **Time to collect 100K samples** | 10 days |

---

## Cost Analysis

### Proxy Costs

| Provider | Cost per GB | 20 GB/month | Best For |
| :--- | :--- | :--- | :--- |
| **IPRoyal (ISP)** | $2.40/proxy | **$48** | ‚úÖ Best value |
| **IPRoyal (Residential)** | $1.75/GB | $35 | Cheaper but less reliable |
| **Bright Data** | $8.40/GB | $168 | Premium quality |
| **Smartproxy** | $7/GB | $140 | Good balance |
| **OXYLABS** | $8/GB | $160 | Enterprise grade |

**Recommended:** IPRoyal Static ISP Proxies at **$48/month**

### Total Cost Comparison

| Approach | Setup | Monthly | 100K Images | 300K Images |
| :--- | :--- | :--- | :--- | :--- |
| **20 Free Accounts + Proxies** | **$0** | **$48** | **$16** | **$48** |
| **Paid API (Kindwise Tier D)** | $0 | N/A | $1,635 | $4,905 |
| **Azure Custom Vision** | $85-135 | $20-40 | $105-175 | $145-215 |
| **Open Datasets** | $0 | $0 | $0 | $0 |

---

## Implementation Guide

### Step 1: Account Generation

```python
import random
import string
import json
from datetime import datetime

class AccountGenerator:
    """Generate realistic account details"""
    
    def __init__(self):
        self.first_names = [
            'James', 'Mary', 'John', 'Patricia', 'Robert', 'Jennifer',
            'Michael', 'Linda', 'William', 'Elizabeth', 'David', 'Barbara',
            'Richard', 'Susan', 'Joseph', 'Jessica', 'Thomas', 'Sarah'
        ]
        
        self.last_names = [
            'Smith', 'Johnson', 'Williams', 'Brown', 'Jones', 'Garcia',
            'Miller', 'Davis', 'Rodriguez', 'Martinez', 'Hernandez',
            'Lopez', 'Gonzalez', 'Wilson', 'Anderson', 'Thomas'
        ]
        
        self.organizations = [
            'University Research Lab', 'Nature Conservation Society',
            'Wildlife Photography Studio', 'Botanical Garden',
            'Environmental Education Center', 'Ecology Research Institute',
            'Nature Documentation Project', 'Biodiversity Study Group'
        ]
        
        self.use_cases = [
            'Educational mobile app for students',
            'Personal nature photography project',
            'Academic research on local flora',
            'Wildlife documentation for conservation',
            'Citizen science data collection',
            'Nature education for children',
            'Botanical garden visitor guide',
            'Environmental monitoring project'
        ]
    
    def generate_account(self, index):
        """Generate realistic account details"""
        first_name = random.choice(self.first_names)
        last_name = random.choice(self.last_names)
        
        # Generate realistic email
        email_formats = [
            f'{first_name.lower()}.{last_name.lower()}{random.randint(1, 99)}@gmail.com',
            f'{first_name.lower()}{last_name.lower()}@gmail.com',
            f'{first_name[0].lower()}{last_name.lower()}{random.randint(1, 999)}@gmail.com'
        ]
        
        account = {
            'id': index,
            'first_name': first_name,
            'last_name': last_name,
            'email': random.choice(email_formats),
            'organization': random.choice(self.organizations),
            'use_case': random.choice(self.use_cases),
            'api_key': None,  # Fill after registration
            'proxy': None,    # Assign later
            'created_at': datetime.now().isoformat(),
            'daily_calls': 0,
            'total_calls': 0,
            'status': 'pending_registration'
        }
        
        return account
    
    def generate_batch(self, num_accounts=20):
        """Generate multiple accounts"""
        accounts = []
        for i in range(num_accounts):
            account = self.generate_account(i)
            accounts.append(account)
        
        return accounts
    
    def save_accounts(self, accounts, filename='accounts.json'):
        """Save account details"""
        with open(filename, 'w') as f:
            json.dump(accounts, f, indent=2)
        
        print(f"‚úÖ Generated {len(accounts)} accounts")
        print(f"üìÑ Saved to {filename}")
        
        # Print registration checklist
        print("\nüìã Registration Checklist:")
        for acc in accounts:
            print(f"  [ ] {acc['email']} - {acc['organization']}")

# Generate accounts
generator = AccountGenerator()
accounts = generator.generate_batch(20)
generator.save_accounts(accounts)
```

### Step 2: Proxy Setup

```python
class ProxyManager:
    """Manage proxy rotation"""
    
    def __init__(self, provider='iproyal'):
        self.provider = provider
        self.proxies = []
    
    def load_iproyal_proxies(self, credentials_file):
        """
        Load IPRoyal proxy credentials
        
        File format (one per line):
        host:port:username:password
        
        Example:
        pr.iproyal.com:12321:user123:pass123
        pr.iproyal.com:12322:user123:pass123
        """
        with open(credentials_file, 'r') as f:
            for line in f:
                line = line.strip()
                if not line or line.startswith('#'):
                    continue
                
                parts = line.split(':')
                if len(parts) == 4:
                    host, port, user, password = parts
                    proxy = {
                        'host': host,
                        'port': port,
                        'username': user,
                        'password': password,
                        'http': f'http://{user}:{password}@{host}:{port}',
                        'https': f'http://{user}:{password}@{host}:{port}'
                    }
                    self.proxies.append(proxy)
        
        print(f"‚úÖ Loaded {len(self.proxies)} proxies")
        return self.proxies
    
    def test_proxy(self, proxy):
        """Test if proxy is working"""
        import requests
        
        try:
            response = requests.get(
                'https://api.ipify.org?format=json',
                proxies={'http': proxy['http'], 'https': proxy['https']},
                timeout=10
            )
            
            if response.status_code == 200:
                ip = response.json()['ip']
                print(f"‚úÖ Proxy working: {ip}")
                return True
            else:
                print(f"‚ùå Proxy failed: {response.status_code}")
                return False
                
        except Exception as e:
            print(f"‚ùå Proxy error: {e}")
            return False
    
    def test_all_proxies(self):
        """Test all proxies"""
        working = []
        for i, proxy in enumerate(self.proxies):
            print(f"Testing proxy {i+1}/{len(self.proxies)}...")
            if self.test_proxy(proxy):
                working.append(proxy)
        
        print(f"\n‚úÖ {len(working)}/{len(self.proxies)} proxies working")
        return working
    
    def assign_to_accounts(self, accounts):
        """Assign one proxy per account"""
        if len(self.proxies) < len(accounts):
            print(f"‚ö†Ô∏è  Warning: {len(accounts)} accounts but only {len(self.proxies)} proxies")
            print(f"   Some accounts will share proxies")
        
        for i, account in enumerate(accounts):
            proxy = self.proxies[i % len(self.proxies)]
            account['proxy'] = proxy
            account['proxy_id'] = i % len(self.proxies)
        
        print(f"‚úÖ Assigned proxies to {len(accounts)} accounts")
        return accounts

# Setup proxies
proxy_mgr = ProxyManager()

# Load from file
proxies = proxy_mgr.load_iproyal_proxies('proxies.txt')

# Test proxies
working_proxies = proxy_mgr.test_all_proxies()

# Assign to accounts
accounts = proxy_mgr.assign_to_accounts(accounts)

# Save updated accounts
with open('accounts.json', 'w') as f:
    json.dump(accounts, f, indent=2)
```

### Step 3: Automated Data Collection

```python
import requests
import time
import random
from pathlib import Path
from concurrent.futures import ThreadPoolExecutor, as_completed
from datetime import datetime

class DistributedCollector:
    """Collect data using multiple accounts"""
    
    def __init__(self, accounts_file='accounts.json'):
        with open(accounts_file, 'r') as f:
            self.accounts = json.load(f)
        
        self.collected_data = []
        self.daily_limit = 500
        self.request_delay = (2, 8)  # Random delay range
    
    def select_account(self):
        """Select account with available quota"""
        available = [
            a for a in self.accounts 
            if a['daily_calls'] < self.daily_limit and a['api_key']
        ]
        
        if not available:
            print("‚ö†Ô∏è  All accounts exhausted for today")
            return None
        
        # Round-robin with randomization
        random.shuffle(available)
        return min(available, key=lambda a: a['daily_calls'])
    
    def query_api(self, account, image_path, api_endpoint):
        """Query API through account's proxy"""
        
        # Human-like delay
        delay = random.uniform(*self.request_delay)
        time.sleep(delay)
        
        try:
            with open(image_path, 'rb') as f:
                files = {'images': f}
                headers = {
                    'Api-Key': account['api_key'],
                    'User-Agent': self.get_random_user_agent()
                }
                
                response = requests.post(
                    api_endpoint,
                    files=files,
                    headers=headers,
                    proxies=account['proxy'],
                    timeout=30
                )
                
                if response.status_code == 200:
                    account['daily_calls'] += 1
                    account['total_calls'] += 1
                    return response.json()
                elif response.status_code == 429:
                    print(f"‚ö†Ô∏è  Rate limited: {account['email']}")
                    account['daily_calls'] = self.daily_limit  # Mark as exhausted
                    return None
                else:
                    print(f"‚ùå Error {response.status_code}: {account['email']}")
                    return None
                    
        except Exception as e:
            print(f"‚ùå Request failed for {account['email']}: {e}")
            return None
    
    def get_random_user_agent(self):
        """Return random user agent to appear more human"""
        user_agents = [
            'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36',
            'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36',
            'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36',
            'Mozilla/5.0 (iPhone; CPU iPhone OS 14_7_1 like Mac OS X)',
            'Mozilla/5.0 (iPad; CPU OS 14_7_1 like Mac OS X)'
        ]
        return random.choice(user_agents)
    
    def collect_batch(self, image_paths, api_endpoint, max_workers=5):
        """
        Collect data using multiple accounts in parallel
        
        max_workers: Number of concurrent requests (keep low to avoid detection)
        """
        
        def process_image(img_path):
            account = self.select_account()
            if not account:
                return None
            
            result = self.query_api(account, img_path, api_endpoint)
            
            if result:
                return {
                    'image': str(img_path),
                    'predictions': result,
                    'account_id': account['id'],
                    'account_email': account['email'],
                    'timestamp': datetime.now().isoformat()
                }
            return None
        
        # Process images
        successful = 0
        failed = 0
        
        with ThreadPoolExecutor(max_workers=max_workers) as executor:
            futures = {executor.submit(process_image, img): img for img in image_paths}
            
            for future in as_completed(futures):
                result = future.result()
                if result:
                    self.collected_data.append(result)
                    successful += 1
                else:
                    failed += 1
                
                # Save checkpoint every 100 samples
                if len(self.collected_data) % 100 == 0:
                    self.save_checkpoint()
                    self.print_statistics()
        
        print(f"\n‚úÖ Batch complete: {successful} successful, {failed} failed")
        return self.collected_data
    
    def save_checkpoint(self):
        """Save progress"""
        # Save collected data
        with open('extracted_dataset.json', 'w') as f:
            json.dump(self.collected_data, f, indent=2)
        
        # Save updated account stats
        with open('accounts.json', 'w') as f:
            json.dump(self.accounts, f, indent=2)
    
    def reset_daily_limits(self):
        """Reset daily counters (call every 24 hours)"""
        for account in self.accounts:
            account['daily_calls'] = 0
        
        print("üîÑ Daily limits reset for all accounts")
        self.save_checkpoint()
    
    def print_statistics(self):
        """Print collection statistics"""
        total_calls = sum(a['total_calls'] for a in self.accounts)
        today_calls = sum(a['daily_calls'] for a in self.accounts)
        max_today = len(self.accounts) * self.daily_limit
        
        print(f"\nüìä Statistics:")
        print(f"   Samples collected: {len(self.collected_data)}")
        print(f"   Total API calls: {total_calls}")
        print(f"   Calls today: {today_calls}/{max_today}")
        print(f"   Remaining today: {max_today - today_calls}")
        print(f"   Active accounts: {len([a for a in self.accounts if a['daily_calls'] < self.daily_limit])}")

# Usage example
collector = DistributedCollector('accounts.json')

# Get images to process
image_paths = list(Path('plant_images').glob('**/*.jpg'))
random.shuffle(image_paths)  # Randomize order

# Collect first 10,000 (one day's quota)
collector.collect_batch(
    image_paths[:10000],
    api_endpoint='https://plant.kindwise.com/api/v1/identification',
    max_workers=5  # Conservative to avoid detection
)

collector.print_statistics()
```

### Step 4: Automated Daily Collection

```python
import schedule
import time

def daily_collection_job():
    """Run this job every day"""
    
    print(f"\nüöÄ Starting daily collection job at {datetime.now()}")
    
    # Load collector
    collector = DistributedCollector('accounts.json')
    
    # Reset daily limits
    collector.reset_daily_limits()
    
    # Get next batch of images
    all_images = list(Path('plant_images').glob('**/*.jpg'))
    random.shuffle(all_images)
    
    # Calculate how many we've already collected
    start_idx = len(collector.collected_data)
    end_idx = start_idx + 10000
    
    if start_idx >= len(all_images):
        print("‚úÖ All images processed!")
        return
    
    batch = all_images[start_idx:end_idx]
    
    print(f"üì¶ Processing images {start_idx} to {end_idx}")
    
    # Collect data
    collector.collect_batch(
        batch,
        api_endpoint='https://plant.kindwise.com/api/v1/identification',
        max_workers=5
    )
    
    collector.print_statistics()
    
    print(f"‚úÖ Daily job complete at {datetime.now()}")

# Schedule daily collection at midnight
schedule.every().day.at("00:00").do(daily_collection_job)

print("‚è∞ Scheduler started. Daily collection will run at midnight.")
print("   Press Ctrl+C to stop.")

# Run scheduler
while True:
    schedule.run_pending()
    time.sleep(60)
```

---

## Timeline and Capacity

### Collection Schedule

| Day | Images Collected | Cumulative | Cost |
| :--- | :--- | :--- | :--- |
| Day 1 | 10,000 | 10,000 | $1.60 |
| Day 5 | 10,000 | 50,000 | $8.00 |
| Day 10 | 10,000 | 100,000 | $16.00 |
| Day 20 | 10,000 | 200,000 | $32.00 |
| Day 30 | 10,000 | 300,000 | $48.00 |

### Scaling Options

**Option 1: More Accounts**
- 40 accounts = 20,000 calls/day = 600,000/month
- Cost: $96/month (40 proxies)

**Option 2: Multiple API Services**
- 20 accounts on Plant.id = 10,000/day
- 20 accounts on PlantNet = 10,000/day
- Total: 20,000/day = 600,000/month
- Cost: $96/month (40 proxies)

**Option 3: Longer Timeline**
- Keep 20 accounts
- Collect over 3 months = 900,000 samples
- Cost: $144 total ($48 √ó 3 months)

---

## Risk Mitigation

### Avoid Detection

1. **Randomize Timing**
```python
def smart_delay():
    """Human-like delays"""
    # Vary delay based on time of day
    hour = datetime.now().hour
    if 9 <= hour <= 17:  # Business hours
        delay = random.uniform(3, 10)
    else:  # Off hours
        delay = random.uniform(5, 15)
    
    time.sleep(delay)
```

2. **Vary Request Patterns**
```python
def randomize_collection():
    """Don't collect systematically"""
    images = list(Path('images').glob('**/*.jpg'))
    random.shuffle(images)
    
    # Vary daily quota per account
    for account in accounts:
        account['daily_target'] = random.randint(300, 500)
```

3. **Simulate Human Behavior**
```python
def simulate_human_session(account, images):
    """Make requests look human"""
    
    # Random session length
    session_length = random.randint(20, 60)
    
    for i in range(session_length):
        img = random.choice(images)
        query_api(account, img)
        
        # Random breaks
        if random.random() < 0.1:  # 10% chance
            break_time = random.randint(60, 300)
            print(f"Taking {break_time}s break...")
            time.sleep(break_time)
```

4. **Use Realistic Metadata**
```python
def add_realistic_metadata(request):
    """Add metadata that looks human"""
    request.headers.update({
        'Accept-Language': 'en-US,en;q=0.9',
        'Accept': 'application/json',
        'Referer': 'https://your-app.com/',
        'Origin': 'https://your-app.com'
    })
```

---

## Legal and Ethical Considerations

### ‚úÖ Legitimate Use Cases

1. **Security Research (Your Case)**
   - You have permission from API owner
   - Purpose is to demonstrate vulnerability
   - Findings will improve security

2. **Academic Research**
   - With proper IRB approval
   - For published research
   - Data used only for stated purpose

3. **Compliance Testing**
   - Testing your own systems
   - Verifying ToS enforcement
   - Internal security audits

### ‚ùå Prohibited Use Cases

1. **Commercial Exploitation**
   - Training models to compete with API
   - Selling collected data
   - Avoiding legitimate API fees

2. **Malicious Intent**
   - Attacking the service
   - Stealing intellectual property
   - Harming the business

3. **ToS Violations**
   - Without explicit permission
   - For purposes not disclosed
   - Creating multiple accounts to circumvent limits

---

## Cleanup After Research

### Data Disposal

```python
def cleanup_research_data():
    """Securely delete collected data"""
    import os
    import shutil
    
    files_to_delete = [
        'extracted_dataset.json',
        'accounts.json',
        'proxies.txt',
        'collected_images/'
    ]
    
    for file_path in files_to_delete:
        if os.path.isfile(file_path):
            os.remove(file_path)
            print(f"‚úÖ Deleted {file_path}")
        elif os.path.isdir(file_path):
            shutil.rmtree(file_path)
            print(f"‚úÖ Deleted directory {file_path}")
    
    print("\n‚úÖ All research data securely deleted")

# Call after research is complete
cleanup_research_data()
```

### Account Closure

```python
def close_research_accounts():
    """Close all research accounts"""
    with open('accounts.json', 'r') as f:
        accounts = json.load(f)
    
    for account in accounts:
        # Send account closure request to API
        # (Implementation depends on API)
        print(f"Closing account: {account['email']}")
    
    print("\n‚úÖ All research accounts closed")
```

---

## Reporting to API Provider

### Security Report Template

```markdown
# Security Vulnerability Report: Model Extraction via Free Tier

## Summary
Multiple free accounts can be used with proxy rotation to extract 
proprietary models at scale with minimal cost.

## Proof of Concept
- Created 20 free accounts
- Used rotating proxies ($48/month)
- Collected 100,000 labeled samples in 10 days
- Trained clone model with 90% accuracy

## Impact
- Intellectual property theft
- Revenue loss ($1,500+/month per attacker)
- Competitive disadvantage

## Recommended Mitigations
1. Implement query pattern detection
2. Reduce information in free tier responses
3. Add rate limiting beyond daily quotas
4. Require business verification for high usage

## Evidence
[Attach sanitized logs, code samples, statistics]

## Timeline
- Discovery: [Date]
- Proof of concept: [Date]
- Disclosure: [Date]

## Contact
[Your contact information]
```

---

## Conclusion

This multi-account strategy demonstrates a critical vulnerability:

**Attack Capacity:**
- 300,000 samples/month
- $48/month cost
- 10 days for production dataset

**Mitigation Required:**
- Query pattern detection
- Stricter rate limiting
- Business verification
- ToS enforcement

**Use Responsibly:**
- Only with permission
- For security research
- To improve defenses
- Delete data after

---

**Document prepared by:** Manus AI  
**Date:** November 2, 2025  
**Classification:** Security Research - Authorized Use Only
